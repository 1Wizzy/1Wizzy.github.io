---
title: "批量下载浏器开发者工具捕获到的资源"
date: 2025-03-15 13:22
categories: ['Useful_Scripts', 'Python']
tags: ['Python', 'HAR', 'Browser Developer Tools']
---

## 相比于其他方法的优点:

1. 爬虫，该方法需根据网页元素定制
2. 提取 HTML 中的🔗，该方法无法捕获需要动态加载的资源

## 步骤：

1. 打开浏览器的开发者工具（F12 or Ctrl+Shift+I）
2. 切换至网络tab（Network）
3. 将你想要下载的资源全部被捕获（可以通过开发者工具自带的筛选功能查看是否齐全）
4. 导出 HAR 文件
5. 运行 Python Code

## Code

```py
import json
import os
import requests

# HAR 文件路径
har_file_path = 'Your HAR FILE PATH'

# 创建保存图片的文件夹
download_folder = 'downloaded_images'
os.makedirs(download_folder, exist_ok=True)

# 解析 HAR 文件
with open(har_file_path, 'r', encoding='utf-8') as f:
    har_data = json.load(f)

# 遍历所有请求，筛选图片
image_urls = []
for entry in har_data['log']['entries']:
    response = entry['response']
    if 'content' in response and 'mimeType' in response['content']:
        mime_type = response['content']['mimeType']
        if mime_type.startswith('image/'): # 筛选图片
            url = entry['request']['url']
            image_urls.append(url)

# 下载图片
for i, url in enumerate(image_urls):
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()  # 检查是否请求成功
        # 生成文件名，此处的例子是：例如url:www.xxx.com/123.jpg 此处的文件名即为‘123.jpg’ 文件名逻辑可能需要修改
        filename = os.path.join(download_folder, url.split('?')[0].split('/')[-1]) 
        with open(filename, 'wb') as f:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)
        print(f"Download Success: {url}")
    except Exception as e:
        print(f"Download Failed: {url}, ERROR: {str(e)}")

print("Dowload Complete.")
```

> 注意：你需要保证提取出的 URL 可以被不被依赖地访问

